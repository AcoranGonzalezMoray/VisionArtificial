{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "# mode and so on\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#MTCNN face detector\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "#deepface\n",
    "from deepface import DeepFace\n",
    "from deepface.commons import functions\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_embs(X, batch_size=2):\n",
    "    norm_images = prewhiten(X)\n",
    "    pd = []\n",
    "    for start in range(0, len(norm_images), batch_size):\n",
    "        pd.append(model.predict_on_batch(norm_images[start:start+batch_size]))\n",
    "    return l2_normalize(np.concatenate(pd))\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y\n",
    "\n",
    "# Designed for UTKFace as filename contains biometric information\n",
    "def TrainEmbedingsUTKFace(folders,outputfile):\n",
    "    nimgs = 0\n",
    "    Xorig = []\n",
    "    X = []\n",
    "    Gender = []\n",
    "    Age = []\n",
    "    Etnia = []\n",
    "    \n",
    "    for directory in folders:\n",
    "        #print(directory)\n",
    "        for path, subdirs, files in os.walk(directory):\n",
    "            for name in files:\n",
    "                #print(name)\n",
    "                if name.endswith(\".jpg\") and nimgs < 2000:\n",
    "                #if name.endswith(\".png\"): # and nimgs < 3000:\n",
    "                    img_path = os.path.join(path, name)\n",
    "                    #print(img_path)\n",
    "\n",
    "                    image = cv2.imread(img_path)\n",
    "\n",
    "                    if (type(image) is np.ndarray):\n",
    "                        #print(img_path)\n",
    "                        # Search face \n",
    "                        values = DetectLargestFaceEyesMTCNN(image)\n",
    "                        if values is not None:\n",
    "                            #print(nimgs)\n",
    "                            face, eyes, shape = values\n",
    "\n",
    "                            # draws container\n",
    "                            [x, y, w, h] = face\n",
    "                            if x > -1:\n",
    "                                # Eyes\n",
    "                                [lex, ley, rex, rey] = eyes\n",
    "                                if lex > -1:\n",
    "                                    \n",
    "                                    B, G, R = cv2.split(image)\n",
    "\n",
    "                                    # Normalize for Facenet\n",
    "                                    normalizatorHS.normalize_gray_img(B, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                                    Bnorm = normalizatorHS.normf_image\n",
    "                                    normalizatorHS.normalize_gray_img(G, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                                    Gnorm = normalizatorHS.normf_image\n",
    "                                    normalizatorHS.normalize_gray_img(R, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                                    Rnorm = normalizatorHS.normf_image\n",
    "                                    NormBGRHS = cv2.merge((Bnorm, Gnorm, Rnorm))\n",
    "                                    #cv2.imshow(\"Normalized\", NormBGRHS)\n",
    "\n",
    "                                    # Cropping from HS for facenet\n",
    "                                    # Usa nyoki https://github.com/nyoki-mtl/keras-facenet\n",
    "                                    NormBGR = NormBGRHS[35:115, 39:119, :]\n",
    "\n",
    "                                    # SOft biometric data are extracted from filename\n",
    "                                    if NormBGR is not None:\n",
    "                                        nimgs = nimgs + 1\n",
    "                                        #print(nimgs)\n",
    "\n",
    "                                        fsub = name.find('_')\n",
    "                                        sage = name[:fsub]\n",
    "                                        #print(sage)\n",
    "                                        sub = name[fsub + 1:]\n",
    "                                        fsub = sub.find('_')\n",
    "                                        sgender = sub[:fsub]\n",
    "                                        sub = sub[fsub + 1:]\n",
    "                                        fsub = sub.find('_')\n",
    "                                        setnia = sub[:fsub]\n",
    "\n",
    "                                        # print(name)\n",
    "                                        # print(sage)\n",
    "                                        # print(sgender)\n",
    "                                        # print(setnia)\n",
    "                                        # print(nimgs)\n",
    "\n",
    "                                        # Facenet kearas expects 160x160\n",
    "                                        #imaged = cv2.resize(NormBGR, (160, 160))\n",
    "                                        \n",
    "                                        # Obtiene embeddings\n",
    "                                        imaged = cv2.resize(NormBGR, dim, interpolation = cv2.INTER_AREA)\n",
    "                                        \n",
    "                                        # Mantengo originales para mostrar parecido\n",
    "                                        imager = cv2.resize(image, (200, 200), interpolation=cv2.INTER_AREA)\n",
    "                                        Xorig.append(imager)\n",
    "                                        # Facenet\n",
    "                                        X.append(imaged)\n",
    "                                        Gender.append(sgender)\n",
    "                                        Age.append(sage)\n",
    "                                        Etnia.append(setnia)\n",
    "    \n",
    "    if nimgs > 0:\n",
    "        # Compute embeddings \n",
    "        embs = calc_embs(np.array(X))\n",
    "\n",
    "        print(\"Salvando embs\")\n",
    "        fid = open(outputfile, \"wb\")\n",
    "\n",
    "        pickle.dump([nimgs, X, embs, Age, Gender, Etnia], fid)\n",
    "        print(embs.shape)\n",
    "        fid.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSimilarNN(X,idxsimilar, nbrs, embs, Title):\n",
    "    # Gets nearest neighbors\n",
    "    distance, indices = nbrs.kneighbors(embs)\n",
    "    minp = indices[0][0]\n",
    "\n",
    "    # Keeps copy of last grames NN\n",
    "    idxsimilar.extend(indices[0])\n",
    "\n",
    "    # Remove old ones when more than nframes accumulated\n",
    "    if len(idxsimilar) > kvecinos * nframeskvecinos:\n",
    "        idxsimilar = idxsimilar[kvecinos:]\n",
    "\n",
    "    # print('Lista con ' + str(len(idxsimilar)) + ' ' + str(idxsimilar) + '\\n')\n",
    "\n",
    "    # enough history\n",
    "    if len(idxsimilar) > kvecinos:\n",
    "        minp = GetClosesetMode(idxsimilar)\n",
    "\n",
    "    # Larger for visualization\n",
    "    imageS = cv2.resize(X[minp], (320, 320))\n",
    "\n",
    "    # Soft biometrics labels\n",
    "    if len(idxsimilar) > 0:\n",
    "        modesG = stats.mode([Gender[int(i)] for i in idxsimilar])\n",
    "        modesE = stats.mode([Etnia[int(i)] for i in idxsimilar])\n",
    "        edad = np.array([int(Age[int(i)]) for i in idxsimilar]).mean()\n",
    "\n",
    "        if modesG[0][0] == '0':\n",
    "            gen = 'M'\n",
    "        else:\n",
    "            gen = 'F'\n",
    "\n",
    "        if modesE[0][0] == '0':\n",
    "            et = 'B'\n",
    "        elif modesE[0][0] == '1':\n",
    "            et = 'N'\n",
    "        elif modesE[0][0] == '2':\n",
    "            et = 'A'\n",
    "        elif modesE[0][0] == '3':\n",
    "            et = 'H'\n",
    "        else:\n",
    "            et = 'L'\n",
    "\n",
    "        cv2.putText(imageS, '%s %s %d (%s)' % (gen, et, int(edad), Age[minp]), (10, 30), font, 0.5, (255, 255, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(Title, imageS)\n",
    "\n",
    "    return idxsimilar\n",
    "\n",
    "def getLargestMTCNNBB(objects):\n",
    "        if len(objects) < 1:\n",
    "            return -1\n",
    "        elif len(objects) == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            areas = [ (det['box'][2]*det['box'][3]) for det in objects ]\n",
    "            return np.argmax(areas)\n",
    "        \n",
    "def DetectLargestFaceEyesMTCNN(img):\n",
    "    global detectormtcnn\n",
    "    \n",
    "    results = detectormtcnn.detect_faces(img)\n",
    "\n",
    "    if not results is None:\n",
    "        index = getLargestMTCNNBB(results)\n",
    "\n",
    "        if len(results) < 1:\n",
    "            return None\n",
    "\n",
    "        # laergest face\n",
    "        face_info = results[index]\n",
    "\n",
    "        #print(face_info)\n",
    "\n",
    "        [x, y, w, h] = face_info['box']\n",
    "        le = face_info['keypoints']['left_eye']\n",
    "        re = face_info['keypoints']['right_eye']\n",
    "\n",
    "        return [x,y,w,h], [le[0], le[1], re[0], re[1]], [face_info['keypoints']['left_eye'], face_info['keypoints']['right_eye'],\n",
    "                      face_info['keypoints']['nose'], face_info['keypoints']['mouth_left'],\n",
    "                      face_info['keypoints']['mouth_right']]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def ResetDetectionCounters():\n",
    "    global nconsecutivenodetected, nconsecutivedetected, idxsimilarFN\n",
    "\n",
    "    nconsecutivenodetected = nconsecutivenodetected + 1\n",
    "    if nconsecutivenodetected > 10:\n",
    "        nconsecutivedetected = 0\n",
    "        idxsimilarFN = []\n",
    "        \n",
    "def GetClosesetMode(list):\n",
    "    # Get occurrences list\n",
    "    occ = Counter(list)\n",
    "\n",
    "    # Get the mode, if multiple modes present, gets the clostest observing position among beigbors\n",
    "    prima = 0\n",
    "    maxpun = 0\n",
    "    for neighbor, count in occ.most_common(10):\n",
    "        if prima == 0:\n",
    "            prima = 1\n",
    "            mode = count\n",
    "        else:\n",
    "            if count < mode:\n",
    "                break\n",
    "\n",
    "        #print('%s: %7d' % (neighbor, count))\n",
    "\n",
    "        # using enumerate()\n",
    "        # to find indices for 3\n",
    "        neighbor_pos = [i for i, value in enumerate(list) if value == neighbor]\n",
    "        # printing resultant list\n",
    "        #print(\"New indices list : \" + str(neighbor_pos))\n",
    "\n",
    "        pun = 0\n",
    "        for pos in neighbor_pos:\n",
    "            pun = pun + kvecinos - (pos % kvecinos)\n",
    "        #print(pun)\n",
    "        if pun > maxpun:\n",
    "            maxpun = pun\n",
    "            closest_neighbor = neighbor\n",
    "\n",
    "    return closest_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT GLOBAL PARAM \n",
    "\n",
    "detectormtcnn = MTCNN()\n",
    "# Normalization utilities\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "# Embeddings deepface\n",
    "model = DeepFace.build_model(\"Facenet\")\n",
    "target_size = model.layers[0].input_shape\n",
    "dim = (int(target_size[0][1]), int(target_size[0][2]))\n",
    "\n",
    "# 1 to create a new appearance dataset\n",
    "creadataset = 0\n",
    "if creadataset == 1:\n",
    "    print(\"Create model\")\n",
    "    #Dataset folders\n",
    "    folders = [\"D:/Datasets/Caras/UTKFace/part1\", \"D:/Datasets/Caras/UTKFace/part2\",\n",
    "            \"D:/Datasets/Caras/UTKFace/part3\"]\n",
    "    TrainEmbedingsUTKFace(folders,\"D:/FACEScode_models/UTKFace_DLIB_Nyoki_deepfaceSP2021.obj\")\n",
    "    \n",
    "#MODIFICAR EN BASE A TU RUTA\n",
    "fid = open(\"D:/TEMPORAL/UTKFace_DLIB_Nyoki.obj\", \"rb\") #Modelo reducido\n",
    "nimgs, X_FN, embsFN, Age, Gender, Etnia = pickle.load(fid)\n",
    "\n",
    "# Tree for KNN search\n",
    "kvecinos = 10\n",
    "nframeskvecinos = 5\n",
    "nbrsFN = NearestNeighbors(n_neighbors=kvecinos).fit(embsFN)\n",
    "\n",
    "# Initializations\n",
    "debug = 0\n",
    "nconsecutivedetected = 0\n",
    "nconsecutivenodetected = 0\n",
    "idxsimilarFN = []\n",
    "\n",
    "registered = False\n",
    "\n",
    "\n",
    "# Funcion que se utiliza para inicar sesion con codigo y modelo base de Modesto\n",
    "def iniciar_sesion():    \n",
    "    # Face detector\n",
    "    detectormtcnn = MTCNN()\n",
    "    # Normalization utilities\n",
    "    normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "    # Embeddings deepface\n",
    "    model = DeepFace.build_model(\"Facenet\")\n",
    "    target_size = model.layers[0].input_shape\n",
    "    dim = (int(target_size[0][1]), int(target_size[0][2]))\n",
    "\n",
    "    # 1 to create a new appearance dataset\n",
    "    creadataset = 0\n",
    "    if creadataset == 1:\n",
    "        print(\"Create model\")\n",
    "        #Dataset folders\n",
    "        folders = [\"D:/Datasets/Caras/UTKFace/part1\", \"D:/Datasets/Caras/UTKFace/part2\",\n",
    "                \"D:/Datasets/Caras/UTKFace/part3\"]\n",
    "        TrainEmbedingsUTKFace(folders,\"D:/FACEScode_models/UTKFace_DLIB_Nyoki_deepfaceSP2021.obj\")\n",
    "\n",
    "    #MODIFICAR EN BASE A TU RUTA\n",
    "    fid = open(\"D:/TEMPORAL/UTKFace_DLIB_Nyoki.obj\", \"rb\") #Modelo reducido\n",
    "\n",
    "    nimgs, X_FN, embsFN, Age, Gender, Etnia = pickle.load(fid)\n",
    "\n",
    "\n",
    "    # Tree for KNN search\n",
    "    kvecinos = 10\n",
    "    nframeskvecinos = 5\n",
    "    nbrsFN = NearestNeighbors(n_neighbors=kvecinos).fit(embsFN)\n",
    "\n",
    "    # Initializations\n",
    "    debug = 0\n",
    "    nconsecutivedetected = 0\n",
    "    nconsecutivenodetected = 0\n",
    "    idxsimilarFN = []\n",
    "\n",
    "    registered = False\n",
    "    user = ''\n",
    "\n",
    "\n",
    "    # Fonts\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # Leemos las caras registradas\n",
    "    path = \"./DataAlbum/BaseUsuarios/\"\n",
    "    filesEmbs = []\n",
    "    files = os.listdir(path)\n",
    "    NNReg = []\n",
    "\n",
    "    # Calculamos el vector de embeddings de las caras de la carpeta Registered\n",
    "    for file_name in os.listdir(path):\n",
    "        print(file_name)\n",
    "        file_name = path + \"/\" + file_name\n",
    "        imgReg = cv2.imread(file_name)\n",
    "        B, G, R = cv2.split(imgReg)\n",
    "        # Search face \n",
    "        values = DetectLargestFaceEyesMTCNN(imgReg)\n",
    "        if values is not None:\n",
    "            face, eyes, shape = values\n",
    "\n",
    "            #draws face container\n",
    "            [x, y , w, h] = face\n",
    "            if x > -1:\n",
    "                cv2.rectangle(imgReg, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                # draws eyes and mask if available\n",
    "                [lex, ley, rex, rey] = eyes\n",
    "                if lex > -1:                \n",
    "                    nconsecutivedetected = nconsecutivedetected + 1  #11?\n",
    "                    nconsecutivenodetected = 0\n",
    "                    \n",
    "                    # HS normalization for facenet\n",
    "                    normalizatorHS.normalize_gray_img(B, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Bnorm = normalizatorHS.normf_image\n",
    "                    normalizatorHS.normalize_gray_img(G, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Gnorm = normalizatorHS.normf_image\n",
    "                    normalizatorHS.normalize_gray_img(R, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Rnorm = normalizatorHS.normf_image\n",
    "                    NormBGRHS = cv2.merge((Bnorm, Gnorm, Rnorm))\n",
    "                    NormBGR = NormBGRHS[35:115, 39:119, :]\n",
    "                    \n",
    "                    # Obtiene embeddings\n",
    "                    img1 = cv2.resize(NormBGR, dim, interpolation = cv2.INTER_AREA)\n",
    "                    #embs = model.predict(img1[None,...])\n",
    "                    embs = calc_embs(np.array([img1]))\n",
    "                    \n",
    "                    filesEmbs.append(embs)\n",
    "                \n",
    "                    NNReg.append(NearestNeighbors(n_neighbors=kvecinos).fit(embs))\n",
    "\n",
    "\n",
    "    # Webcam connection, check unitl one is located\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Check for other cameras\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            cap = cv2.VideoCapture(2)\n",
    "            if not cap.isOpened():\n",
    "                print('Camera error')\n",
    "                exit(0)\n",
    "            else:\n",
    "                print('Camera 2')\n",
    "        else:\n",
    "            print('Camera 1')\n",
    "    else:\n",
    "        print('Camera 2')\n",
    "        \n",
    "    #Set camera resolution\n",
    "    cap.set(3,640);\n",
    "    cap.set(4,480);\n",
    "\n",
    "    while True:\n",
    "        arr = []\n",
    "        # Get frame\n",
    "        t = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        # For HS normalization split channels\n",
    "        B, G, R = cv2.split(frame)\n",
    "        \n",
    "        captureFrame = frame.copy()\n",
    "\n",
    "        # Search face \n",
    "        values = DetectLargestFaceEyesMTCNN(frame)\n",
    "        if values is not None:\n",
    "            face, eyes, shape = values\n",
    "\n",
    "            #draws face container\n",
    "            [x, y , w, h] = face\n",
    "            if x > -1:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "                # draws eyes and mask if available\n",
    "                [lex, ley, rex, rey] = eyes\n",
    "                if lex > -1:                \n",
    "                    nconsecutivedetected = nconsecutivedetected + 1  #11?\n",
    "                    nconsecutivenodetected = 0\n",
    "                        \n",
    "                    # Show detected facial elements\n",
    "                    for (x, y) in shape:\n",
    "                        cv2.circle(frame, (x, y), 2, (255, 255, 255), -1)\n",
    "                    cv2.circle(frame, ((int)(lex), (int)(ley)), 4, (0, 0, 255), -1)\n",
    "                    cv2.circle(frame, ((int)(rex), (int)(rey)), 4, (0, 255, 0), -1)\n",
    "\n",
    "                    # HS normalization for facenet\n",
    "                    normalizatorHS.normalize_gray_img(B, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Bnorm = normalizatorHS.normf_image\n",
    "                    normalizatorHS.normalize_gray_img(G, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Gnorm = normalizatorHS.normf_image\n",
    "                    normalizatorHS.normalize_gray_img(R, lex, ley, rex, rey, faceutils.Kind_wraping.HS)\n",
    "                    Rnorm = normalizatorHS.normf_image\n",
    "                    NormBGRHS = cv2.merge((Bnorm, Gnorm, Rnorm))\n",
    "                    cv2.imshow(\"Normalized\", NormBGRHS)\n",
    "                        \n",
    "                    # Cropping from HS for facenet\n",
    "                    # De HS a lo proximadamente usa nyok https://github.com/nyoki-mtl/keras-facenet\n",
    "                    NormBGR = NormBGRHS[35:115, 39:119, :]\n",
    "                    cv2.imshow(\"Normalizedc\", NormBGR)\n",
    "                    \n",
    "                    # Obtiene embeddings\n",
    "                    img1 = cv2.resize(NormBGR, dim, interpolation = cv2.INTER_AREA)\n",
    "                    #embs = model.predict(img1[None,...])\n",
    "                    embs = calc_embs(np.array([img1]))\n",
    "                    \n",
    "                    #Comprobamos que el vector de embeddings ya tiene los embeddings de todas las \n",
    "                    # caras registradas\n",
    "                    \n",
    "                    if (len(filesEmbs) == len(files)):\n",
    "                        \n",
    "                        # Recorremos el vector de embeddings\n",
    "                        for i in range(len(filesEmbs)):\n",
    "                            cv2.putText(frame, 'Reconociendo, ESPERE.....', (10, 50), font, 0.5, (0, 0, 255))\n",
    "                            sim = cosine_similarity(embs, filesEmbs[i])\n",
    "                            arr.append(sim)\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            # Comprobamos que de todas las imágenes registradas, la que más parecido tiene,\n",
    "                            # tiene una similitud superior al 60%\n",
    "                            if (np.max(arr) > 0.6): registered = True                \n",
    "                            else : registered = False\n",
    "                    \n",
    "                else:\n",
    "                    ResetDetectionCounters()\n",
    "            else:\n",
    "                ResetDetectionCounters()\n",
    "        else:\n",
    "            ResetDetectionCounters()\n",
    "\n",
    "        if debug:\n",
    "            print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "        # Show resulting image\n",
    "        cv2.imshow('Cam', frame)\n",
    "        \n",
    "        # Esc to finish\n",
    "        tec = cv2.waitKey(5)\n",
    "        if tec & tec == 27:  # Esc\n",
    "            break  \n",
    "        \n",
    "        if(registered):  user = files[np.argmax(arr)]\n",
    "        break  \n",
    "            \n",
    "        \n",
    "    # Close windows and release camera\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return [registered, user]\n",
    "\n",
    "\n",
    "\n",
    "def registrarse(nombreImagen):\n",
    "    # Pulse espacio para tomar la foto y cambie el nombre de la imagen por su nombre.\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Check for other cameras\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            cap = cv2.VideoCapture(2)\n",
    "            if not cap.isOpened():\n",
    "                print('Camera error')\n",
    "                exit(0)\n",
    "            else:\n",
    "                print('Camera 2')\n",
    "        else:\n",
    "            print('Camera 1')\n",
    "    else:\n",
    "        print('Camera 2')\n",
    "        \n",
    "    #Set camera resolution\n",
    "    cap.set(3,640);\n",
    "    cap.set(4,480);\n",
    "\n",
    "    while True:\n",
    "        # Get frame\n",
    "        t = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        cp_frame = frame.copy()\n",
    "\n",
    "        # Show resulting image\n",
    "        cv2.imshow('Cam', frame)\n",
    "        \n",
    "        tec = cv2.waitKey(5)\n",
    "        if tec & tec == 27:  # Esc\n",
    "            break\n",
    "        \n",
    "        if tec & tec == 32 : # Espacio\n",
    "            cv2.imwrite(f'./DataAlbum/BaseUsuarios/{nombreImagen}.jpg', cp_frame ) #Cambiar al nombre de usuario deseado\n",
    "            # Crear carpeta dentro de ./DataAlbum/Galeria\n",
    "            user_folder = os.path.join(\"./DataAlbum\", \"Galeria\", nombreImagen)\n",
    "            os.makedirs(user_folder, exist_ok=True)\n",
    "            break\n",
    "        \n",
    "    # Close windows and release camera\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERFAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 2\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import threading\n",
    "import time\n",
    "from tkinter import messagebox, simpledialog, ttk\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "\n",
    "class EmotionInfoWindow:\n",
    "    def __init__(self, root, emotion_info, image_path):\n",
    "        self.root = root\n",
    "        self.root.title(\"Información de Emociones\")\n",
    "\n",
    "        # Dividir la ventana en dos secciones\n",
    "        self.image_frame = tk.Frame(root, width=100, height=200)\n",
    "        self.info_frame = tk.Frame(root)\n",
    "\n",
    "        self.image_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        self.info_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Mostrar la imagen en la izquierda\n",
    "        profile_image = Image.open(image_path)\n",
    "        profile_image = profile_image.resize((150, 150), Image.ADAPTIVE)\n",
    "        profile_photo = ImageTk.PhotoImage(profile_image)\n",
    "        self.image_label = tk.Label(self.image_frame, image=profile_photo)\n",
    "        self.image_label.image = profile_photo\n",
    "        self.image_label.pack(pady=10)\n",
    "\n",
    "        # Mostrar la información en la derecha\n",
    "        self.label_age = ttk.Label(self.info_frame, text=f\"Age: {emotion_info['age']}\")\n",
    "        self.label_race = ttk.Label(self.info_frame, text=f\"Race: {emotion_info['dominant_race']}\")\n",
    "        self.label_emotion = ttk.Label(self.info_frame, text=f\"Emotion: {emotion_info['dominant_emotion']}\")\n",
    "        self.label_gender = ttk.Label(self.info_frame, text=f\"Gender: {emotion_info['dominant_gender']}\")\n",
    "        self.label_image_path = ttk.Label(self.info_frame, text=f\"Image Path: {image_path}\")\n",
    "\n",
    "        # Ubicar las etiquetas en la ventana\n",
    "        self.label_age.pack(pady=10)\n",
    "        self.label_race.pack(pady=10)\n",
    "        self.label_emotion.pack(pady=10)\n",
    "        self.label_gender.pack(pady=10)\n",
    "        self.label_image_path.pack(pady=10)\n",
    "\n",
    "        # Calcular la posición para colocar la ventana encima de la pantalla principal\n",
    "        width, height = 400, 200  # Ajusta según sea necesario\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        x = root.winfo_x() + (root.winfo_width() - width) // 2\n",
    "        y = root.winfo_y() - height - 10  # Ajusta según sea necesario\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "\n",
    "        # Establecer la geometría de la ventana\n",
    "        self.root.geometry(f\"{width}x{height}+{int(x)}+{int(y)}\")\n",
    "\n",
    "class PhotoAlbumApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Photo Album App\")\n",
    "        # Contenedor principal\n",
    "        self.main_frame = tk.Frame(root)\n",
    "        self.main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Contenedor para las imágenes con scrollbar\n",
    "        self.image_frame = tk.Frame(self.main_frame)\n",
    "        self.image_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.image_frame, width=320, height=480)\n",
    "        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.scrollbar = tk.Scrollbar(self.image_frame, command=self.canvas.yview)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.canvas.configure(yscrollcommand=self.scrollbar.set)\n",
    "\n",
    "        # Contenedor interno para las imágenes\n",
    "        self.image_container = tk.Frame(self.canvas)\n",
    "        self.canvas.create_window((0, 0), window=self.image_container, anchor=tk.NW)\n",
    "\n",
    "        # Crear un Frame para actuar como separador\n",
    "        separator_frame = tk.Frame(self.main_frame, width=2, bg=\"black\")\n",
    "        separator_frame.pack(side=tk.LEFT, fill=tk.Y, padx=10)\n",
    "\n",
    "        # Contenedor para la información del usuario\n",
    "        self.user_info_frame = tk.Frame(self.main_frame, width=320, height=480)\n",
    "        self.user_info_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.label = tk.Label(self.user_info_frame, text=\"Bienvenido\")\n",
    "        self.label.pack(pady=10)\n",
    "\n",
    "        self.loading_label = tk.Label(self.user_info_frame, text=\"Cargando...\", fg=\"red\")\n",
    "        self.loading_label.pack_forget()  # Ocultar inicialmente\n",
    "\n",
    "        self.register_label = tk.Label(self.user_info_frame, text=\"Usuario no registrado...\", fg=\"red\")\n",
    "        self.register_label.pack_forget()  # Ocultar inicialmente\n",
    "\n",
    "        # Añadir una etiqueta para la foto de perfil\n",
    "        self.profile_photo = tk.Label(self.user_info_frame)\n",
    "        self.profile_photo.pack(pady=10)\n",
    "\n",
    "        self.data = tk.Label(self.user_info_frame, text=\"Data: \")\n",
    "        self.dataInfo = tk.Label(self.user_info_frame, text=\"\")\n",
    "\n",
    "        #LOG\n",
    "        self.btn_capture = tk.Button(self.user_info_frame, text=\"Iniciar Sesion\", command=self.iniciar_sesion)\n",
    "        self.btn_capture.pack(pady=10)\n",
    "        self.btn_capture_r = tk.Button(self.user_info_frame, text=\"Registrarse\", command=self.registrar_usuario)\n",
    "        self.btn_capture_r.pack(pady=10)\n",
    "        # Crear el botón para agregar imágenes\n",
    "        self.btn_add_image = tk.Button(self.user_info_frame, text=\"Agregar Imagen al Album\", command=self.agregar_imagen)\n",
    "        self.btn_logout = tk.Button(self.user_info_frame, text=\"Cerrar Sesion\", command=self.cerrar_sesion)\n",
    "\n",
    "\n",
    "        self.canvas.bind(\"<Button-1>\", self.on_image_click)  # Asociar evento de clic a la función\n",
    "        self.user_folder = \"User\"\n",
    "        self.data_folder = \"DataAlbum/Galeria/\"\n",
    "        self.profile_folder = \"DataAlbum/BaseUsuarios/\"\n",
    "        self.photo_path = \"\"\n",
    "        self.photo_references = []  # Lista para almacenar las referencias a las imágenes\n",
    "        self.user_name = \"\"\n",
    "\n",
    "    def iniciar_sesion(self):\n",
    "        # Efectuar el reconocimiento facial \n",
    "         # Mostrar etiqueta de \"Cargando...\"\n",
    "        self.loading_label.pack(pady=10)\n",
    "        \n",
    "        # Iniciar sesión en un hilo separado\n",
    "        login_thread = threading.Thread(target=self.realizar_inicio_sesion)\n",
    "        login_thread.start()\n",
    "        \n",
    "\n",
    "    def realizar_inicio_sesion(self):\n",
    "        # Lógica para iniciar sesión\n",
    "        result = iniciar_sesion()\n",
    "\n",
    "        # Ocultar etiqueta de \"Cargando...\"\n",
    "        self.loading_label.pack_forget()\n",
    "\n",
    "        if result[0]:\n",
    "            print(\"Inicio exitoso\")\n",
    "            user_name = result[1].split('.')[0]\n",
    "            if user_name:\n",
    "                user_name = user_name.strip()\n",
    "                self.user_name = user_name\n",
    "\n",
    "                self.initUser()\n",
    "                self.btn_add_image.pack(pady=10)\n",
    "                self.btn_capture.pack_forget()\n",
    "                self.btn_capture_r.pack_forget()\n",
    "                self.data.pack(pady=10)\n",
    "                self.dataInfo.pack(pady=10)\n",
    "                self.btn_logout.pack(pady=10)\n",
    "\n",
    "                user_path = os.path.join(self.data_folder, user_name)\n",
    "                self.load_and_display_images(user_path)\n",
    "                self.image_container.update_idletasks()\n",
    "                self.canvas.config(scrollregion=self.canvas.bbox(\"all\"))\n",
    "        else:\n",
    "            #self.registrar_usuario()\n",
    "            self.register_label.pack(pady=10)\n",
    "            print(\"Usuario no registrado\")\n",
    "\n",
    "    def initUser(self):\n",
    "        self.label.config(text=f\"Bienvenido, {self.user_name}\")\n",
    "\n",
    "        profile_photo_path = os.path.join(self.profile_folder, f\"{self.user_name}.jpg\")\n",
    "        if os.path.exists(profile_photo_path):\n",
    "            print(\"existe\")\n",
    "            profile_image = Image.open(profile_photo_path)\n",
    "            profile_image = profile_image.resize((100, 100), Image.ADAPTIVE)\n",
    "            profile_photo = ImageTk.PhotoImage(profile_image)\n",
    "            self.profile_photo.configure(image=profile_photo)\n",
    "            self.profile_photo.pack(pady=10)\n",
    "            self.profile_photo.image = profile_photo  # Mantener una referencia para evitar que se elimine la imagen\n",
    "            obj = DeepFace.analyze(profile_photo_path, enforce_detection=False, actions=['age', 'gender', 'race', 'emotion'])\n",
    "            self.dataInfo.config(text=f\"Name: {self.user_name}\\nAge: {obj[0]['age']}\\nGender: {obj[0]['dominant_gender']}\\nEmotion: {obj[0]['dominant_emotion']} \")\n",
    "\n",
    "    def registrar_usuario(self):\n",
    "        self.register_label.pack_forget()\n",
    "        self.loading_label.pack(pady=10)\n",
    "        # Utilizar simpledialog para obtener el nombre de usuario\n",
    "        user_name = simpledialog.askstring(\"Registrarse\", \"Ingrese su nombre de usuario:\")\n",
    "        if user_name:\n",
    "            # Llamar a la función registrarse con el nombre de usuario\n",
    "\n",
    "            login_thread = threading.Thread(target=self.registrarse_con_nombre(user_name))\n",
    "            login_thread.start()\n",
    "\n",
    "            \n",
    "           \n",
    "\n",
    "    def registrarse_con_nombre(self, user_name):\n",
    "        try:\n",
    "            # Guardar la imagen con el nombre de usuario proporcionado\n",
    "            registrarse(user_name)\n",
    "            self.loading_label.pack_forget()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error al registrar usuario: {str(e)}\")\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def cerrar_sesion(self):\n",
    "            # Restaurar el estado inicial al cerrar la sesión\n",
    "            self.user_name = \"\"\n",
    "            self.photo_references = []\n",
    "            self.photo_path = \"\"\n",
    "            self.label.config(text=\"Bienvenido\")\n",
    "            self.data.pack_forget()\n",
    "            self.profile_photo.pack_forget()\n",
    "            self.dataInfo.pack_forget()\n",
    "            self.btn_logout.pack_forget()\n",
    "            self.btn_capture.pack(pady=10)\n",
    "            self.btn_capture_r.pack(pady=10)\n",
    "            self.btn_add_image.pack_forget()\n",
    "            self.canvas.delete(\"all\")\n",
    "\n",
    "\n",
    "    def load_and_display_images(self, folder):\n",
    "        # Cargar las imágenes y almacenar las referencias a PhotoImage\n",
    "        self.photo_references = []  # Limpiar la lista de referencias a las imágenes\n",
    "\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(folder, filename)\n",
    "                image = Image.open(img_path)\n",
    "                image.thumbnail((100, 100))  # Ajustar el tamaño según sea necesario\n",
    "                photo = ImageTk.PhotoImage(image)\n",
    "\n",
    "                # Almacenar la referencia a la imagen\n",
    "                self.photo_references.append((img_path, photo))\n",
    "\n",
    "        # Mostrar las imágenes en el canvas\n",
    "        self.display_images()\n",
    "\n",
    "    def agregar_imagen(self):\n",
    "        # Abrir un cuadro de diálogo para que el usuario seleccione una imagen\n",
    "        file_path = filedialog.askopenfilename(title=\"Seleccionar Imagen\", filetypes=[(\"Imagen\", \"*.png;*.jpg;*.jpeg\")])\n",
    "\n",
    "        # Verificar si el usuario seleccionó una imagen\n",
    "        if file_path:\n",
    "            # Aquí puedes realizar cualquier lógica adicional que necesites con la nueva imagen\n",
    "            print(f\"Imagen seleccionada: {file_path}\")\n",
    "\n",
    "            # Por ejemplo, podrías cargar y mostrar la nueva imagen en el canvas\n",
    "            image = Image.open(file_path)\n",
    "            image.thumbnail((100, 100))  # Ajusta el tamaño según sea necesario\n",
    "            photo = ImageTk.PhotoImage(image)\n",
    "\n",
    "            # Almacenar la referencia a la nueva imagen\n",
    "            self.photo_references.append((file_path, photo))\n",
    "\n",
    "            # Mostrar las imágenes actualizadas en el canvas\n",
    "            self.display_images()\n",
    "            \n",
    "            # Obtener la carpeta del usuario\n",
    "            user_path = os.path.join(self.data_folder, self.user_name)\n",
    "\n",
    "            # Copiar la nueva imagen al directorio del usuario\n",
    "            shutil.copy(file_path, user_path)\n",
    "\n",
    "    def display_images(self):\n",
    "        # Código para mostrar las imágenes en el canvas\n",
    "        # Puedes adaptar este código según tus necesidades\n",
    "        self.canvas.delete(\"all\")  # Limpiar el canvas\n",
    "\n",
    "        for i, (photo_path, photo) in enumerate(self.photo_references):\n",
    "            x_offset = (i % 4) * 120\n",
    "            y_offset = (i // 4) * 120\n",
    "            img_id = self.canvas.create_image(x_offset, y_offset, anchor=tk.NW, image=photo)\n",
    "            self.canvas.tag_bind(img_id, \"<Button-1>\", lambda event, path=photo_path: self.on_image_click(event, path))\n",
    "\n",
    "    def on_image_click(self, event, image_path):\n",
    "        # Función llamada al hacer clic en una imagen\n",
    "        self.photo_path = image_path\n",
    "        self.analyze_emotion()\n",
    "\n",
    "    def analyze_emotion(self):\n",
    "        # Analizar emociones usando DeepFace\n",
    "        obj = DeepFace.analyze(self.photo_path, enforce_detection=False, actions=['age', 'gender', 'race', 'emotion'])\n",
    "        if obj and isinstance(obj, list):\n",
    "            self.show_emotion_info_window(obj[0], self.photo_path)\n",
    "        else:\n",
    "            print(\"No se encontraron resultados de análisis de emociones.\")\n",
    "\n",
    "    def show_emotion_info_window(self, emotion_info, image_path):\n",
    "        # Calcular la posición para colocar la ventana encima de la ventana principal\n",
    "        width, height = 450, 250  # Ajusta según sea necesario\n",
    "        screen_width = self.root.winfo_screenwidth()\n",
    "        screen_height = self.root.winfo_screenheight()\n",
    "        x = self.root.winfo_x() + (self.root.winfo_width() - width) // 2\n",
    "        y = self.root.winfo_y() + (self.root.winfo_height() - height) // 2\n",
    "\n",
    "        # Crear una nueva ventana para mostrar la información de emociones\n",
    "        window = tk.Toplevel(self.root)\n",
    "        emotion_info_window = EmotionInfoWindow(window, emotion_info, image_path)\n",
    "\n",
    "        # Establecer la geometría de la nueva ventana\n",
    "        window.geometry(f\"{width}x{height}+{int(x)}+{int(y)}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = PhotoAlbumApp(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
